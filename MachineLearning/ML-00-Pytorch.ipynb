{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "[Pytorch](https://pytorch.org/) is the most popular open-source, modern deep learning library out there and what we will use in this tutorial session. Other popular libraries include [Tensorflow](https://www.tensorflow.org/), [JAX](https://docs.jax.dev/en/latest/quickstart.html), [MindSpore](https://www.mindspore.cn/en/), etc. ...\n",
    "\n",
    "![market-share](https://softwaremill.com/user/pages/blog/229.ml-engineer-comparison-of-pytorch-tensorflow-jax-and-flax/image2.png?g-2f9bce85)\n",
    "\n",
    "*Trends of paper implementations grouped by framework: Comparison of  PyTorch vs. TensorFlow ([viso.ai](https://viso.ai/deep-learning/pytorch-vs-tensorflow/))*\n",
    "\n",
    "All of those libraries works in similar fashion. Common things you have to learn include:\n",
    "\n",
    "1. Array data types (_tensor_)\n",
    "2. Data loading tools (streamline prepping data into appropraite types from input files)\n",
    "3. Implementation of a machine learning (ML) model\n",
    "\n",
    "In this notebook, we cover the basics of the first item.\n",
    "\n",
    "<a href=\"datatype\"></a>\n",
    "## 1. Tensor data types in PyTorch\n",
    "In `PyTorch`, we use `torch.Tensor` objects to represent data arrays. It is a lot like `numpy.ndarray` objects, but not quite the same. `torch` provide an application programming interface (API) to easily convert data between `numpy.ndarray` and `torch.Tensor`. Let's play a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x719fd9d712b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set the seed to always get the same result from RNG calls in this notebook\n",
    "SEED = 123\n",
    "np.random.seed(SEED)    # Setting the seed for reproducibility\n",
    "torch.manual_seed(SEED) # This is how you do for torch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... yep, that's how we set pytorch random number seed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a torch.Tensor\n",
    "\n",
    "`PyTorch` provides constructors similar to numpy (named the same way wherever possible to avoid users having to look-up function names). Here are some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.zeros:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "torch.ones:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "torch.arange:\n",
      " tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "\n",
      "torch.randn:\n",
      " tensor([[-0.1115,  0.1204, -0.3696],\n",
      "        [-0.2404, -1.1969,  0.2093]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor of 0s = numpy.zeros\n",
    "t = torch.zeros(2,3)\n",
    "print('torch.zeros:\\n', t)\n",
    "\n",
    "# Tensor of 1s = numpy.ones\n",
    "t = torch.ones(2, 3)\n",
    "print('\\ntorch.ones:\\n',t)\n",
    "\n",
    "# Tensor from a sequential integers = numpy.arange\n",
    "t = torch.arange(0, 6, 1).reshape(2,3).float()\n",
    "print('\\ntorch.arange:\\n',t)\n",
    "\n",
    "# Normal distribution centered at 0.0 and sigma=1.0 = numpy.rand.randn\n",
    "t = torch.randn(2, 3)\n",
    "print('\\ntorch.randn:\\n',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or you can create from a simple list, tuple, and numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy data\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "torch.Tensor data\n",
      " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "\n",
      "Python list : [1, 2, 3]\n",
      "torch.Tensor: tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Create a 10x10 numpy array\n",
    "data_np = np.zeros([10,10],dtype=np.float32)\n",
    "\n",
    "# Fill it with something\n",
    "np.fill_diagonal(data_np, 1.)\n",
    "print('Numpy data\\n',data_np)\n",
    "\n",
    "# Create torch.Tensor from the numpy array\n",
    "data_torch = torch.Tensor(data_np)\n",
    "print('\\ntorch.Tensor data\\n',data_torch)\n",
    "\n",
    "# One can make also from a list\n",
    "data_list = [1, 2, 3]\n",
    "data_list_torch = torch.Tensor(data_list)\n",
    "print('\\nPython list :', data_list)\n",
    "print('torch.Tensor:', data_list_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting back from `torch.Tensor` to a numpy array can be easily done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numpy data (converted back from torch.Tensor)\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Bringing back into numpy array\n",
    "data_np = data_torch.numpy()\n",
    "print('\\nNumpy data (converted back from torch.Tensor)\\n',data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary operations that can be performed on an array in `numpy` also exist in `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean tensor(0.1000) std tensor(0.3015) sum tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "# Mean, standard deviation and sum\n",
    "print('mean', data_torch.mean(), 'std',data_torch.std(), 'sum', data_torch.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the return of those functions (`mean`,`std`,`sum`) are tensor objects. If you would like a single scalar value, you can call `item` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.10000000149011612 std 0.30151134729385376 sum 10.0\n"
     ]
    }
   ],
   "source": [
    "# Mean, standard deviation and sum\n",
    "print('mean', data_torch.mean().item(), 'std',data_torch.std().item(), 'sum', data_torch.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic linear algebra operations\n",
    "Common operations include element-wise addition, substraction, multiplication, matrix multiplication, and reshaping. Read the [documentation](https://pytorch.org/docs/stable/tensors.html) to find the right function for what you want to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two numpy matrices\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[1. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      "Adding a scalar to all elements:\n",
      "tensor([[2., 1., 1.],\n",
      "        [1., 2., 1.],\n",
      "        [1., 1., 2.]])\n",
      "\n",
      "torch.Tensor matrix addition:\n",
      "tensor([[2., 1., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "\n",
      "torch.Tensor matrix substraction:\n",
      "tensor([[ 0., -1., -1.],\n",
      "        [ 0.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.]])\n",
      "torch.Tensor element-wise multiplication:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "torch.Tensor matrix multiplication:\n",
      "tensor([[1., 1., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Start by initializing two matrices of zeros\n",
    "data_a = np.zeros([3,3], dtype=np.float32)\n",
    "data_b = np.zeros([3,3], dtype=np.float32)\n",
    "\n",
    "# Fill the first one's diagonal with ones\n",
    "np.fill_diagonal(data_a, 1.)\n",
    "\n",
    "# Fill the second ones' first row with ones\n",
    "data_b[0] = 1.\n",
    "\n",
    "# Print the matrices\n",
    "print('Two numpy matrices')\n",
    "print(data_a)\n",
    "print(data_b,'\\n')\n",
    "\n",
    "# Cast them to torch.Tensor objects\n",
    "torch_a = torch.Tensor(data_a)\n",
    "torch_b = torch.Tensor(data_b)\n",
    "\n",
    "print('\\nAdding a scalar to all elements:')\n",
    "print(torch_a + 1)\n",
    "\n",
    "print('\\ntorch.Tensor matrix addition:')\n",
    "print(torch_a + torch_b)\n",
    "\n",
    "print('\\ntorch.Tensor matrix substraction:')\n",
    "print(torch_a - torch_b)\n",
    "\n",
    "print('torch.Tensor element-wise multiplication:')\n",
    "print(torch_a*torch_b)\n",
    "\n",
    "print('\\ntorch.Tensor matrix multiplication:')\n",
    "print(torch_a@torch_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping\n",
    "\n",
    "You can access the tensor shape via `.shape` attribute, just like numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "torch_a shape: torch.Size([3, 3])\n",
      "The 0th dimension size: 3\n"
     ]
    }
   ],
   "source": [
    "print(torch_a)\n",
    "print('torch_a shape:', torch_a.shape)\n",
    "print('The 0th dimension size:', torch_a.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, there is a `reshape` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch_a.reshape(1,9))\n",
    "torch_a.reshape(1,9).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and you can also use -1 in the same way you used for numpy (infer one dimension from the others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch_a.reshape(-1,3))\n",
    "torch_a.reshape(-1,3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing (Slicing)\n",
    "\n",
    "We can use a similar indexing trick like we tried with a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch a specific row..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_a[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also generate a mask based on a boolean condition..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [ True, False,  True],\n",
       "        [ True,  True, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch_a == 0.\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which can than be used to slice an array (access or modify specific elements of it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_a[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU acceleration\n",
    "Putting `torch.Tensor` on GPU is very easy, provided you have access to a CUDA-enabled GPU, i.e. an Nvidia device. This can be checks easily using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by checking the number of visible CUDA devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above commands return `True` and an integer strictly above `0`, we can move torch.Tensor to GPU!\n",
    "- `t.cuda()` will place the tensor on the first available GPU device\n",
    "- `t.to('cuda')` will place the tensor on the first available GPU device\n",
    "- `t.to(device=0)` will place the tensor on the `rank=0` (first in the `nvidia-smi` list)\n",
    "\n",
    "The latter command allows to place the data on a specific GPU, if several of them are available. This is of particular interest when training a model across multiple GPUs for faster convergence.\n",
    "\n",
    "If there are no visible GPUs, the rest of the notebook will not execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two arrays with an identical data type, shape, and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large 1000x1000 matrix\n",
    "data_np = np.zeros([1000, 1000],dtype=np.float32)\n",
    "data_cpu = torch.Tensor(data_np).to('cpu')\n",
    "# data_gpu = torch.Tensor(data_np).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use jupyter notebook's profiling tools to estimate how long it takes to compute the fifth power of the matrix on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 ms ± 10 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mean = (data_cpu ** 5).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and next on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# mean = (data_gpu ** 5).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which is more than x10 faster than the cpu counter part :)\n",
    "\n",
    "But there's a catch you should be aware! Preparing a data on GPU does take time because data needs to be sent to GPU, which could take some time. Let's compare the time it takes to create a tensor on CPU v.s. GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.8 μs ± 359 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_np = np.zeros([1000, 1000], dtype=np.float32)\n",
    "data_cpu = torch.Tensor(data_np).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# data_np = np.zeros([1000, 1000], dtype=np.float32)\n",
    "# data_gpu = torch.Tensor(data_np).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it takes nearly 10 times longer to create this particular data tensor on our GPU. This speed depends on many factors including your hardware configuration (e.g. CPU-GPU communication via PCI-e or NVLINK). It makes sense to move computations that take longer than the data transfer time to be performed on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
